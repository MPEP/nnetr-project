---
title: "Perzeptron Algorithmus"
author: "Mario Peplinski"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Einführung
Künstliche neuronale Netze bilden die modelltechnische Grundlage für einige der aktuell am stärksten wachsenden Forschungsfelder im Kontext der künstlichen Intelligenz allgemein und insbesondere auf dem Teilgebiet des maschinellen Lernens. Der seit 2006 zu beobachtende Popularitätszuwachs ist vorallem auf die Entdeckung effizienterer Trainingsstrategien zurückzuführen die seither unter dem Begriff Deep Learning eine eigene Klasse innerhalb der Disziplin des maschinellen Lernens bilden. Während das Ziel bei früheren Modellierungsansätzen noch darin bestand die biologische Funktionsweise des Gehirns nachzuempfinden, hat sich die moderne Interpretation des künstlichen neuronalen Netzwerks bereits stark von der neurowissenschaftlichen Perspektive zu Gunsten einer abstrakteren Sichtweise der beobachteten Zusammenhänge entfernt. [Vgl. @2016goodfellow]

Ein künstliches neuronales Netz wird demnach als ein Berechnungsmodell auf Grundlage einer Netzwerkstruktur interpretiert, wobei der minimale Anweisungssatz zur Implementierung primitiver Funktionen in den Knoten des Netzwerks enthalten ist und die Kompositionsregeln implizit aus den Verbindungsstruktur abgeleitet werden, die die Knoten untereinander besitzen. Jedes einzelne Netzwerkelement entspricht somit einer primitiven Funktion und die Gesamtheit aller Netzwerkelemente kann als Netzwerk primitiver Funktionen betrachtet werden. Konkrete Implementierung künstlicher neuronaler Netze unterscheiden sich in der Regel meist nur bezüglich der verwendeten primitiven Funktionen, der Struktur der Verbindungen zwischen den Netzwerkelementen oder dem Zeitpunkt der Informationsübertragung zwischen den Netzwerkknoten, weshalb das oben beschriebene Modell als Prototyp eines künstlichen neuronalen Netzes betrachtet werden kann. [Vgl. @1996rojas]

Neuronale Netze werden aufgrund ihrer Funktionsweise der Klasse der sogenannten überwachten Lernverfahren zugerechnet. Kennzeichnend für Verfahren dieser Klasse ist einerseits, dass der Lernprozess unter dem Gesichtspunkt einer konkreten Zielsetzung vollzogen wird, welche im Vorfeld bereits bekannt ist und andererseits, dass der Trainingsdatensatz Informationen über die Zielvariable enthält. Wenn ein entsprechender Trainingsdatensatz verfügbar ist, lassen sich auf Grundlage der darin enthalteten Informationen eine Reihe von Hypothesen bezüglich der vorliegende Problemstellung aufstellen, wobei der Typus des funktionalen, linearen Zusammenhangs die einfachste und am weitesten erforschte Hypothesenform darstellt und daher im Weiteren als Grundannahme für die Vorstellung des implementierten Verfahrens dienen soll. [Vgl. @2000christianini]

Mit dem nnetr Package soll die Implementierung eines linearen Klassifikationsverfahrens auf Grundlage eines einlagigen, neuralen Netzwerks in R demonstriert werden. Das einlagige, neuronale Netzwerk welches gemeinhin auch als einlagiges Perzeptron bezeichnet wird, besteht lediglich aus einer Reihe von Eingangsknoten und einem einzelnen Ausgangsknoten und stellt damit die einfachste Ausprägung eines neuronalen Netzes dar. Das Ziel des Klassifikationsverfahrens besteht darin, unter Verwendung eines vorgegebenen Trainigsdatensatzes und einer vordefinierten Entscheidungsregel, iterativ eine lineare Funktion zu erlernen, die bei Eingabe eine Merkmalskombination die zugehörige Instanz einer von zwei bereits bekannten Klassen zuordnet.

# Das Perzeptron Modell
Das klassische Perzeptron Modell nach @1958rosenblatt beschreibt ein hypothetisches System zur Verbeitung sensorischer Reize. Das System besteht aus einer Menge hierachisch organisierter Zellen die in Schichten angeordnet sind und jeweils über eine oder mehrere eingehende und ausgehende Verbindung zu Zellen in vorhergehenden oder nachfolgenden Schichten verfügen. Die Intention hinter der Entwicklung dieses Modell bestand darin, die fundamentalen Eigenschaften intelligenter Systeme zu illustrieren, weshalb sich die Darstellung nach Rosenblatt strukturell stark am Aufbau des Nervensystems biologischer Lebewesen orientiert. [Vgl. 1958rosenblatt]

Im Kontext des klassischen Perzeptron-Modells wird ein betrachtetes Zellnetzwerk in drei hintereinander angeordnete Wirkungsräume beziehungsweise Schichten unterteilt. Einen Projektionsoberfläche, welche in Anlehnung an das photosensorische System biologischer Organismen als Retina bezeichnet wird, eine Assoziationsschicht, die ihrerseits wiederum in einen Projektions- und einen Assoziationsbereich unterteilt wird, und eine Reaktionsschicht, in der sich die Wirkung des Eingangssignals manifestiert. 

Von einer Projektionsoberfläche werden, als Reaktion auf die Präsenz eines externen Stimulus, binäre Werte an die Zellen der nachgelagerte Projektionsschicht gesendet. Die Information, die dabei von der Singalquelle an das Netzwerk übertragen wird, können, je nach Funktion der Netzwerkelemente, sowohl eine inhibitorische, als auch exzitatorische Wirkung entfalten [vgl. 1958rosenblatt] Die Zellen in der Projektionsschicht fungieren als deterministische, nicht-adaptive Rechnereinheiten, welche die eingehenden Signale interpretieren und in Abhängigkeit von der Intensität der eingehenden Signale ihrerseits wiederum einen Impuls an die Zellen der nachfolgenden Assoziationsschicht senden. [Vgl. 1958rosenblatt]

Die Auslösung der Signalübertragung von den Zellen in der Projektionsschicht an die Zellen in der Assoziationsschich wird mittels einer zellindividuellen Reizschwelle gesteuert. Wenn die Summe aller eingehendenen inhibitorischen und exzitatorischen Signale gleich oder höher als die jeweilige Reizschwelle der betreffenden Zelle ist, wird eine Signalübertragung ausgelöst. Andernfalls bleibt die Signalübertragung aus und der Initialreiz entfaltet keine Wirkung in der Reaktionsschicht.

Der Informationsfluss innerhalb des Netzwerks verläuft zwischen der Projektionsfläche und der Assoziationsschicht unidirektional in Richtung der Assoziationsschicht. Zwischen Assoziations- und Reaktionsschicht besteht hingegen eine bidirektionale Verbindung, wodurch eine Rückmeldung der Zellen in der Reaktionsschicht an die Zellen der vorgelagerten Assoziationsschicht ermöglicht wird. Die Wirkung der Rückmeldung kann dabei prinzipiell entweder exzitatorisch auf die signalgebenden Zellen in der Assoziationsschicht wirken oder eine inhibitorische Wirkung auf alle Zellen in der vorgeschalteten Schicht entfalten, wobei [1958rosenblatt] letzterem Wirkungsmechanismus aus pragmatischen Gründen den Vorzug gab. Dieser Rückwirkungsmechanismus, der auch als Rückpropagierung bezeichnet wird, bildet die Voraussetzung für die Lernfähigkeit des Netzwerks. [Vgl. 1958rosenblatt]

Der eigentliche Lernvorgang vollzieht sich im Verbindungsbereich, zwischen Assoziations- und Reaktionsschicht. Da sich die Zustände der Zellen in der Reaktionsschicht gegenseitig ausschließen, kann die Reaktion des oben beschriebenen Systems nur durch eine der verfügbaren Zellen in der Reaktionsschicht abgebildet werden. Tritt in einem System mit zwei Reaktionszellen R~1 und R~2 die Reaktion R~1 ein, wird durch dieses Ereignis das Eintreten der Reaktion R~2 inhibitiert und umgekehrt. Gesteuert wird dieses Verhalten durch die vorgelagerten Zellen in der Assoziationsschicht. Wenn die Summe aller Impulse die in der Reaktionszelle R~1 eingehen größer ist als die Summe der Impulse die bei Zelle R~2 eingehen, wird R~1 das gesamte verfügbare Aktionspotential absorbieren und dadurch das Eintreten von R~2 hemmen.

Nach dem Eintritt von R~1 wird mittels Rückpropagation sichergestellt, dass die Zellen der Assoziativschicht, die an der Auslösung der Reaktion R~1 beteiligt waren, eine Leistungsverstärkung erfahren. Dies hat den Effekt, dass bei der nächsten Aktivierung der entsprechenden Zellen eine stärkeres Ausgangssignal erzeugt wird, was wiederum den erneuten eintritt von R~1 wahrscheinlicher und den Eintritt von R~2 unwahrscheinlicher macht. Ähnliche Signale auf der Projektionsoberfläche verursachen in der Folge ähnliche Aktivierungsmuster in der Assoziationsschicht und führen nach wiederholter Exposition zu identischen Reaktionen. Das Netzwerk ist nun auf Grundlage der erlernten Merkmale selbstständig eine Klassifikation der Eingangssignale vorzunehmen. [Vgl. 1958rosenblatt]

# Lineare Klassifikation mit Hilfe des Perzeptron Algorithmus


# nnetr
# Beispiel
# Zusammenfassung
